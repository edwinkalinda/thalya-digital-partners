
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// Rate limiting intelligent
const rateLimiter = {
  stt: { requests: 0, resetTime: 0, maxRequests: 2 }, // Plus conservateur
  tts: { requests: 0, resetTime: 0, maxRequests: 2 },
  chat: { requests: 0, resetTime: 0, maxRequests: 8 }
};

const checkRateLimit = (service: 'stt' | 'tts' | 'chat'): boolean => {
  const now = Date.now();
  const limiter = rateLimiter[service];
  
  // Reset si 60 secondes pass√©es
  if (now > limiter.resetTime) {
    limiter.requests = 0;
    limiter.resetTime = now + 60000;
  }
  
  if (limiter.requests >= limiter.maxRequests) {
    console.log(`‚ö†Ô∏è Rate limit atteint pour ${service}, attente...`);
    return false;
  }
  
  limiter.requests++;
  return true;
};

// Cache ULTRA-optimis√© avec pr√©diction intelligente
const ultraCache = new Map<string, { audio: string; response: string; timestamp: number; hitCount: number }>();
const CACHE_TTL = 60 * 60 * 1000; // 1 heure
const MAX_CACHE_SIZE = 100;

// R√©ponses pr√©-g√©n√©r√©es avec audio
const instantResponses = new Map([
  ['bonjour', { text: 'Bonjour ! Comment allez-vous ?', audio: null, priority: 10 }],
  ['hello', { text: 'Hello ! How are you ?', audio: null, priority: 10 }],
  ['salut', { text: 'Salut ! √áa va ?', audio: null, priority: 8 }],
  ['√ßa va', { text: '√áa va bien ! Et vous ?', audio: null, priority: 9 }],
  ['comment allez-vous', { text: 'Tr√®s bien merci ! Et vous ?', audio: null, priority: 7 }],
  ['merci', { text: 'De rien !', audio: null, priority: 6 }],
  ['au revoir', { text: 'Au revoir ! Bonne journ√©e !', audio: null, priority: 5 }],
  ['oui', { text: 'Parfait !', audio: null, priority: 8 }],
  ['non', { text: 'D\'accord.', audio: null, priority: 7 }],
  ['ok', { text: 'Tr√®s bien !', audio: null, priority: 9 }]
]);

// D√©tection de spam/boucles
const spamDetection = new Map<string, { count: number, lastTime: number }>();

const isSpam = (message: string): boolean => {
  const normalized = message.toLowerCase().trim();
  const now = Date.now();
  const spam = spamDetection.get(normalized) || { count: 0, lastTime: 0 };
  
  // Reset si plus de 30 secondes
  if (now - spam.lastTime > 30000) {
    spam.count = 0;
  }
  
  spam.count++;
  spam.lastTime = now;
  spamDetection.set(normalized, spam);
  
  // Consid√©r√© comme spam si plus de 3 fois en 30 secondes
  if (spam.count > 3) {
    console.log(`üö´ Spam d√©tect√©: "${normalized}" (${spam.count} fois)`);
    return true;
  }
  
  return false;
};

let audioPreGenerated = false;

// TTS avec rate limiting et retry
const generateOptimizedTTS = async (text: string): Promise<string | null> => {
  try {
    if (!checkRateLimit('tts')) {
      console.log('‚ö†Ô∏è TTS rate limit atteint, utilisation du cache uniquement');
      return null;
    }

    console.log(`üé§ TTS optimis√©: "${text.substring(0, 30)}..."`);
    const startTime = Date.now();

    const openaiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiKey) {
      console.error('‚ùå Cl√© OpenAI manquante');
      return null;
    }

    const response = await fetch('https://api.openai.com/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'tts-1', // Plus rapide
        input: text,
        voice: 'alloy',
        response_format: 'mp3',
        speed: 1.1 // L√©g√®rement plus rapide
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå Erreur OpenAI TTS:', errorText);
      return null;
    }

    const audioBuffer = await response.arrayBuffer();
    const bytes = new Uint8Array(audioBuffer);
    
    // Conversion base64 optimis√©e
    let binaryString = '';
    const CHUNK_SIZE = 32768;
    
    for (let i = 0; i < bytes.length; i += CHUNK_SIZE) {
      const chunk = bytes.subarray(i, Math.min(i + CHUNK_SIZE, bytes.length));
      binaryString += String.fromCharCode.apply(null, Array.from(chunk));
    }
    
    const base64Audio = btoa(binaryString);
    const latency = Date.now() - startTime;
    console.log(`‚úÖ TTS g√©n√©r√© en ${latency}ms`);
    
    return base64Audio;
  } catch (error) {
    console.error('‚ùå Erreur TTS:', error);
    return null;
  }
};

// Pr√©-g√©n√©ration avec rate limiting
const preGenerateAudio = async () => {
  console.log('üöÄ Pr√©-g√©n√©ration audio...');
  
  let generated = 0;
  for (const [key, data] of instantResponses.entries()) {
    if (generated >= 3) { // Limite pour √©viter rate limit
      console.log('‚ö†Ô∏è Arr√™t pr√©-g√©n√©ration pour √©viter rate limit');
      break;
    }
    
    try {
      const audio = await generateOptimizedTTS(data.text);
      if (audio) {
        data.audio = audio;
        generated++;
        console.log(`‚úÖ Audio pr√©-g√©n√©r√©: "${key}"`);
        // Pause entre g√©n√©rations
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    } catch (error) {
      console.error(`‚ùå Erreur pr√©-g√©n√©ration "${key}":`, error);
    }
  }
  
  audioPreGenerated = true;
  console.log(`üéâ Pr√©-g√©n√©ration termin√©e - ${generated} r√©ponses pr√™tes`);
};

serve(async (req) => {
  const upgrade = req.headers.get("upgrade") || "";
  
  if (upgrade.toLowerCase() !== "websocket") {
    return new Response("Expected WebSocket", { status: 426 });
  }

  const { socket, response } = Deno.upgradeWebSocket(req);
  
  console.log("üöÄ WebSocket √©tabli avec rate limiting");

  if (!audioPreGenerated) {
    preGenerateAudio(); // Non-bloquant
  }

  // Nettoyage cache intelligent
  const cleanCache = () => {
    if (ultraCache.size <= MAX_CACHE_SIZE) return;
    
    const entries = Array.from(ultraCache.entries());
    entries.sort((a, b) => a[1].hitCount - b[1].hitCount);
    
    const toRemove = Math.floor(ultraCache.size * 0.3);
    for (let i = 0; i < toRemove; i++) {
      ultraCache.delete(entries[i][0]);
    }
    
    console.log(`üßπ Cache nettoy√©: ${toRemove} entr√©es`);
  };

  // IA optimis√©e avec rate limiting
  const generateOptimizedAI = async (message: string): Promise<string> => {
    try {
      if (!checkRateLimit('chat')) {
        console.log('‚ö†Ô∏è Chat rate limit atteint, r√©ponse g√©n√©rique');
        return "Je vous √©coute.";
      }

      console.log(`ü§ñ IA optimis√©e: "${message}"`);
      const startTime = Date.now();

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: `Tu es Clara, assistante vocale optimis√©e de Thalya. 
              IMP√âRATIF: R√©ponds en 1 phrase TR√àS courte (max 8 mots fran√ßais).
              Sois naturelle, amicale, directe. √âvite les r√©p√©titions.`
            },
            {
              role: 'user',
              content: message
            }
          ],
          max_tokens: 20,
          temperature: 0.3,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erreur OpenAI Chat:', errorText);
        return "D√©sol√©e, probl√®me technique.";
      }

      const result = await response.json();
      const aiResponse = result.choices[0].message.content;
      const latency = Date.now() - startTime;
      
      console.log(`‚úÖ IA g√©n√©r√©e en ${latency}ms: "${aiResponse}"`);
      return aiResponse;
    } catch (error) {
      console.error('‚ùå Erreur IA:', error);
      return "Probl√®me technique.";
    }
  };

  // Traitement avec rate limiting et anti-spam
  const processMessage = async (message: string) => {
    const startTime = Date.now();
    console.log(`üìù Traitement: "${message}"`);

    const normalizedMessage = message.toLowerCase().trim();
    
    // D√©tection spam
    if (isSpam(normalizedMessage)) {
      socket.send(JSON.stringify({
        type: 'audio_response',
        audioData: null,
        response: "Merci de varier vos questions.",
        latency: Date.now() - startTime,
        source: 'spam_detection'
      }));
      return;
    }
    
    // √âTAPE 1: R√©ponses instantan√©es
    for (const [key, data] of instantResponses.entries()) {
      if (normalizedMessage.includes(key)) {
        const latency = Date.now() - startTime;
        console.log(`‚ö° R√©ponse instantan√©e "${key}" en ${latency}ms`);
        
        if (data.audio && audioPreGenerated) {
          socket.send(JSON.stringify({
            type: 'audio_response',
            audioData: data.audio,
            response: data.text,
            latency: latency,
            source: 'instant_cache'
          }));
          return;
        }
      }
    }

    // √âTAPE 2: Cache intelligent
    cleanCache();
    const cacheKey = normalizedMessage.substring(0, 50);
    const cached = ultraCache.get(cacheKey);
    
    if (cached && (Date.now() - cached.timestamp) < CACHE_TTL) {
      cached.hitCount++;
      const latency = Date.now() - startTime;
      console.log(`üöÄ Cache hit en ${latency}ms`);
      
      socket.send(JSON.stringify({
        type: 'audio_response',
        audioData: cached.audio,
        response: cached.response,
        latency: latency,
        source: 'cache'
      }));
      return;
    }

    // √âTAPE 3: G√©n√©ration avec rate limiting
    try {
      const aiResponse = await generateOptimizedAI(message);
      const aiLatency = Date.now() - startTime;
      
      // Envoi imm√©diat du texte
      socket.send(JSON.stringify({
        type: 'transcription_preview',
        text: aiResponse,
        latency: aiLatency
      }));
      
      // TTS en arri√®re-plan
      const audioData = await generateOptimizedTTS(aiResponse);
      const totalLatency = Date.now() - startTime;
      
      console.log(`‚ö° Traitement total: ${totalLatency}ms`);

      // Cache avec audio
      if (audioData) {
        ultraCache.set(cacheKey, {
          audio: audioData,
          response: aiResponse,
          timestamp: Date.now(),
          hitCount: 1
        });
      }

      socket.send(JSON.stringify({
        type: 'audio_response',
        audioData: audioData,
        response: aiResponse,
        latency: totalLatency,
        source: audioData ? 'generated' : 'text_only'
      }));

    } catch (error) {
      console.error('‚ùå Erreur traitement:', error);
      socket.send(JSON.stringify({
        type: 'error',
        message: 'Erreur technique temporaire',
        latency: Date.now() - startTime
      }));
    }
  };

  socket.onopen = () => {
    console.log("üéâ WebSocket ouvert avec optimisations");
    
    socket.send(JSON.stringify({
      type: 'connection_established',
      message: 'Syst√®me optimis√© avec rate limiting',
      preGenerationStatus: audioPreGenerated ? 'completed' : 'in_progress',
      optimizations: [
        'Rate limiting intelligent',
        'D√©tection anti-spam',
        'Cache avec priorit√©s',
        'R√©ponses instantan√©es',
        'G√©n√©ration parall√®le'
      ]
    }));
  };

  socket.onmessage = async (event) => {
    try {
      const data = JSON.parse(event.data);
      
      switch (data.type) {
        case 'text_message':
          await processMessage(data.message);
          break;
          
        case 'audio_message':
          try {
            if (!checkRateLimit('stt')) {
              console.log('‚ö†Ô∏è STT rate limit atteint, ignor√©');
              socket.send(JSON.stringify({
                type: 'error',
                message: 'Trop de requ√™tes, patientez un moment'
              }));
              return;
            }

            console.log(`üé§ Traitement audio...`);
            
            const audioBlob = new Blob([Uint8Array.from(atob(data.audio), c => c.charCodeAt(0))], { 
              type: 'audio/webm' 
            });
            
            const formData = new FormData();
            formData.append('file', audioBlob, 'audio.webm');
            formData.append('model', 'whisper-1');
            formData.append('language', 'fr');
            formData.append('prompt', 'Clara, bonjour, salut, merci, au revoir, oui, non, ok, comment allez-vous');

            const sttStartTime = Date.now();
            const sttResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
              },
              body: formData,
            });

            if (sttResponse.ok) {
              const sttResult = await sttResponse.json();
              const sttLatency = Date.now() - sttStartTime;
              
              console.log(`‚úÖ STT en ${sttLatency}ms: "${sttResult.text}"`);
              
              socket.send(JSON.stringify({
                type: 'transcription',
                text: sttResult.text,
                latency: sttLatency
              }));
              
              await processMessage(sttResult.text);
            } else {
              const errorText = await sttResponse.text();
              console.error('‚ùå Erreur STT:', errorText);
              socket.send(JSON.stringify({
                type: 'error',
                message: 'Erreur transcription, r√©essayez'
              }));
            }
          } catch (error) {
            console.error('‚ùå Erreur audio:', error);
            socket.send(JSON.stringify({
              type: 'error',
              message: 'Erreur traitement audio'
            }));
          }
          break;
          
        case 'ping':
          socket.send(JSON.stringify({ type: 'pong', timestamp: Date.now() }));
          break;
      }
    } catch (error) {
      console.error('‚ùå Erreur message WebSocket:', error);
    }
  };

  socket.onclose = () => console.log("üîå WebSocket ferm√©");
  socket.onerror = (error) => console.error("‚ùå Erreur WebSocket:", error);

  return response;
});
