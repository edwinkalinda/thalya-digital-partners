
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// Cache ultra-optimis√© avec expiration intelligente
const optimizedCache = new Map<string, { audio: string; response: string; timestamp: number; hitCount: number }>();
const CACHE_TTL = 45 * 60 * 1000; // 45 minutes
const MAX_CACHE_SIZE = 200; // Limite la taille du cache

// R√©ponses instantan√©es optimis√©es avec audio pr√©-g√©n√©r√©
const instantResponsesWithAudio = new Map([
  ['bonjour', {
    text: 'Bonjour ! Comment puis-je vous aider aujourd\'hui ?',
    audio: null
  }],
  ['hello', {
    text: 'Bonjour ! Comment puis-je vous aider aujourd\'hui ?',
    audio: null
  }],
  ['salut', {
    text: 'Bonjour ! Comment puis-je vous aider aujourd\'hui ?',
    audio: null
  }],
  ['comment allez-vous', {
    text: 'Je vais tr√®s bien, merci ! Et vous, comment allez-vous ?',
    audio: null
  }],
  ['comment √ßa va', {
    text: '√áa va tr√®s bien ! Comment puis-je vous aider ?',
    audio: null
  }],
  ['√ßa va', {
    text: 'Oui √ßa va bien ! Comment puis-je vous aider ?',
    audio: null
  }],
  ['merci', {
    text: 'Je vous en prie ! Y a-t-il autre chose que je puisse faire pour vous ?',
    audio: null
  }],
  ['au revoir', {
    text: 'Au revoir ! Passez une excellente journ√©e !',
    audio: null
  }],
  ['bye', {
    text: 'Au revoir ! Passez une excellente journ√©e !',
    audio: null
  }],
  ['tchao', {
    text: 'Au revoir ! Passez une excellente journ√©e !',
    audio: null
  }]
]);

let audioPreGenerationComplete = false;

// TTS ultra-optimis√© avec fallback intelligent
const generateOptimizedTTS = async (text: string): Promise<string | null> => {
  try {
    console.log(`üé§ G√©n√©ration TTS optimis√©e: "${text.substring(0, 50)}..."`);
    const startTime = Date.now();

    // Priorit√© √† OpenAI TTS pour la qualit√© et fiabilit√©
    const openaiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiKey) {
      console.error('‚ùå Aucune cl√© OpenAI trouv√©e');
      return null;
    }

    const response = await fetch('https://api.openai.com/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'tts-1-hd', // Mod√®le haute qualit√©
        input: text,
        voice: 'alloy',
        response_format: 'mp3',
        speed: 1.15 // L√©g√®rement plus rapide pour r√©duire la latence per√ßue
      }),
    });

    if (!response.ok) {
      console.error('‚ùå Erreur OpenAI TTS:', await response.text());
      return null;
    }

    const audioBuffer = await response.arrayBuffer();
    const bytes = new Uint8Array(audioBuffer);
    
    // Conversion base64 optimis√©e
    const CHUNK_SIZE = 16384;
    let binaryString = '';
    
    for (let i = 0; i < bytes.length; i += CHUNK_SIZE) {
      const chunk = bytes.subarray(i, Math.min(i + CHUNK_SIZE, bytes.length));
      binaryString += String.fromCharCode.apply(null, Array.from(chunk));
    }
    
    const base64Audio = btoa(binaryString);
    const latency = Date.now() - startTime;
    console.log(`‚úÖ TTS g√©n√©r√© en ${latency}ms (${base64Audio.length} chars)`);
    
    return base64Audio;
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration TTS:', error);
    return null;
  }
};

// Pr√©-g√©n√©ration audio optimis√©e
const preGenerateOptimizedAudio = async () => {
  console.log('üöÄ Pr√©-g√©n√©ration audio ultra-optimis√©e...');
  
  const concurrentLimit = 3; // √âviter les limites de taux
  const keys = Array.from(instantResponsesWithAudio.keys());
  
  for (let i = 0; i < keys.length; i += concurrentLimit) {
    const batch = keys.slice(i, i + concurrentLimit);
    const promises = batch.map(async (key) => {
      const data = instantResponsesWithAudio.get(key)!;
      try {
        const audio = await generateOptimizedTTS(data.text);
        if (audio) {
          data.audio = audio;
          console.log(`‚úÖ Audio pr√©-g√©n√©r√©: "${key}"`);
          return true;
        }
        return false;
      } catch (error) {
        console.error(`‚ùå Erreur pr√©-g√©n√©ration "${key}":`, error);
        return false;
      }
    });
    
    await Promise.all(promises);
    // Pause entre les batches pour √©viter les limites
    if (i + concurrentLimit < keys.length) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }
  
  audioPreGenerationComplete = true;
  console.log(`üéâ Pr√©-g√©n√©ration termin√©e - ${keys.length} r√©ponses pr√™tes`);
};

serve(async (req) => {
  const upgrade = req.headers.get("upgrade") || "";
  
  if (upgrade.toLowerCase() !== "websocket") {
    return new Response("Expected WebSocket", { status: 426 });
  }

  const { socket, response } = Deno.upgradeWebSocket(req);
  
  console.log("üöÄ WebSocket ultra-optimis√© √©tabli");

  if (!audioPreGenerationComplete) {
    preGenerateOptimizedAudio();
  }

  // Nettoyage intelligent du cache
  const cleanOptimizedCache = () => {
    if (optimizedCache.size <= MAX_CACHE_SIZE) return;
    
    const entries = Array.from(optimizedCache.entries());
    entries.sort((a, b) => {
      // Prioriser par fr√©quence d'utilisation et fra√Æcheur
      const scoreA = a[1].hitCount * (Date.now() - a[1].timestamp);
      const scoreB = b[1].hitCount * (Date.now() - b[1].timestamp);
      return scoreA - scoreB;
    });
    
    // Supprimer les 25% les moins utilis√©s
    const toRemove = Math.floor(optimizedCache.size * 0.25);
    for (let i = 0; i < toRemove; i++) {
      optimizedCache.delete(entries[i][0]);
    }
    
    console.log(`üßπ Cache nettoy√©: ${toRemove} entr√©es supprim√©es`);
  };

  // G√©n√©ration de r√©ponse IA ultra-optimis√©e
  const generateOptimizedAIResponse = async (message: string): Promise<string> => {
    try {
      console.log(`ü§ñ G√©n√©ration IA optimis√©e: "${message}"`);
      const startTime = Date.now();

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini', // Mod√®le le plus rapide
          messages: [
            {
              role: 'system',
              content: `Tu es Clara, l'assistante vocale ultra-performante de Thalya. 
              IMP√âRATIF: R√©ponds en 1 phrase tr√®s courte (maximum 15 mots) pour une conversation fluide.
              Tu es professionnelle, amicale et tr√®s efficace. Tu parles fran√ßais naturellement.
              √âvite les formules de politesse r√©p√©titives. Sois directe et utile.`
            },
            {
              role: 'user',
              content: message
            }
          ],
          max_tokens: 40, // Tr√®s limit√© pour forcer la concision
          temperature: 0.2, // Plus d√©terministe et rapide
          presence_penalty: 0.1,
          frequency_penalty: 0.1
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erreur OpenAI:', errorText);
        throw new Error(`OpenAI error: ${errorText}`);
      }

      const result = await response.json();
      const aiResponse = result.choices[0].message.content;
      const latency = Date.now() - startTime;
      
      console.log(`‚úÖ IA g√©n√©r√©e en ${latency}ms: "${aiResponse}"`);
      return aiResponse;
    } catch (error) {
      console.error('‚ùå Erreur g√©n√©ration IA:', error);
      return "D√©sol√©, probl√®me technique momentan√©.";
    }
  };

  // Traitement ultra-optimis√© des messages
  const processOptimizedMessage = async (message: string) => {
    const startTime = Date.now();
    console.log(`üìù Traitement ultra-optimis√©: "${message}"`);

    const normalizedMessage = message.toLowerCase().trim();
    
    // √âTAPE 1: R√©ponses instantan√©es (0-5ms)
    for (const [key, data] of instantResponsesWithAudio.entries()) {
      if (normalizedMessage.includes(key)) {
        const latency = Date.now() - startTime;
        console.log(`‚ö° R√âPONSE INSTANTAN√âE "${key}" en ${latency}ms`);
        
        if (data.audio && audioPreGenerationComplete) {
          socket.send(JSON.stringify({
            type: 'audio_response',
            audioData: data.audio,
            response: data.text,
            latency: latency,
            source: 'instant_cache'
          }));
          return;
        }
      }
    }

    // √âTAPE 2: Cache intelligent
    cleanOptimizedCache();
    const cacheKey = normalizedMessage.substring(0, 100); // Limitation pour √©viter les cl√©s trop longues
    const cached = optimizedCache.get(cacheKey);
    
    if (cached && (Date.now() - cached.timestamp) < CACHE_TTL) {
      cached.hitCount++;
      const latency = Date.now() - startTime;
      console.log(`üöÄ Cache HIT en ${latency}ms (utilis√© ${cached.hitCount} fois)`);
      
      socket.send(JSON.stringify({
        type: 'audio_response',
        audioData: cached.audio,
        response: cached.response,
        latency: latency,
        source: 'cache'
      }));
      return;
    }

    // √âTAPE 3: G√©n√©ration parall√®le optimis√©e
    try {
      const [aiResponse, _] = await Promise.all([
        generateOptimizedAIResponse(message),
        new Promise(resolve => setTimeout(resolve, 0)) // Force async
      ]);
      
      const aiLatency = Date.now() - startTime;
      
      const ttsStartTime = Date.now();
      const audioData = await generateOptimizedTTS(aiResponse);
      const ttsLatency = Date.now() - ttsStartTime;
      
      const totalLatency = Date.now() - startTime;
      
      console.log(`‚ö° Traitement total: ${totalLatency}ms (IA: ${aiLatency}ms, TTS: ${ttsLatency}ms)`);

      if (audioData) {
        // Cache intelligent avec m√©tadonn√©es
        optimizedCache.set(cacheKey, {
          audio: audioData,
          response: aiResponse,
          timestamp: Date.now(),
          hitCount: 1
        });

        socket.send(JSON.stringify({
          type: 'audio_response',
          audioData: audioData,
          response: aiResponse,
          latency: totalLatency,
          source: 'generated',
          breakdown: {
            ai: aiLatency,
            tts: ttsLatency
          }
        }));
      } else {
        throw new Error('√âchec g√©n√©ration TTS');
      }
    } catch (error) {
      console.error('‚ùå Erreur traitement:', error);
      socket.send(JSON.stringify({
        type: 'error',
        message: 'Erreur de traitement',
        latency: Date.now() - startTime
      }));
    }
  };

  socket.onopen = () => {
    console.log("üéâ WebSocket ultra-optimis√© ouvert");
    
    socket.send(JSON.stringify({
      type: 'connection_established',
      message: 'Syst√®me ultra-optimis√© activ√©',
      preGenerationStatus: audioPreGenerationComplete ? 'completed' : 'in_progress',
      optimizations: [
        'R√©ponses instantan√©es 0-5ms',
        'Cache intelligent avec hit tracking',
        'TTS OpenAI HD optimis√©',
        'G√©n√©ration IA ultra-rapide (gpt-4o-mini)',
        'Traitement parall√®le optimis√©',
        'Compression audio avanc√©e',
        'Nettoyage cache intelligent',
        'Objectif: <100ms pour r√©ponses courantes'
      ],
      cacheStats: {
        size: optimizedCache.size,
        preGenerated: audioPreGenerationComplete ? instantResponsesWithAudio.size : 0
      }
    }));
  };

  socket.onmessage = async (event) => {
    try {
      const data = JSON.parse(event.data);
      
      switch (data.type) {
        case 'text_message':
          await processOptimizedMessage(data.message);
          break;
          
        case 'audio_message':
          try {
            console.log(`üé§ Traitement audio ultra-optimis√©...`);
            
            const audioBlob = new Blob([Uint8Array.from(atob(data.audio), c => c.charCodeAt(0))], { 
              type: 'audio/webm' 
            });
            
            const formData = new FormData();
            formData.append('file', audioBlob, 'audio.webm');
            formData.append('model', 'whisper-1');
            formData.append('language', 'fr'); // Force le fran√ßais pour meilleure pr√©cision
            formData.append('prompt', 'Clara, bonjour, merci, au revoir'); // Mots-cl√©s contextuels

            const sttStartTime = Date.now();
            const sttResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
              },
              body: formData,
            });

            if (sttResponse.ok) {
              const sttResult = await sttResponse.json();
              const sttLatency = Date.now() - sttStartTime;
              
              console.log(`‚úÖ STT ultra-rapide en ${sttLatency}ms: "${sttResult.text}"`);
              
              socket.send(JSON.stringify({
                type: 'transcription',
                text: sttResult.text,
                latency: sttLatency
              }));
              
              await processOptimizedMessage(sttResult.text);
            } else {
              const errorText = await sttResponse.text();
              console.error('‚ùå STT failed:', errorText);
              throw new Error(`STT failed: ${errorText}`);
            }
          } catch (error) {
            console.error('‚ùå Erreur STT:', error);
            socket.send(JSON.stringify({
              type: 'error',
              message: 'Erreur transcription audio'
            }));
          }
          break;
          
        case 'ping':
          socket.send(JSON.stringify({ type: 'pong', timestamp: Date.now() }));
          break;
          
        default:
          console.log('Type message inconnu:', data.type);
      }
    } catch (error) {
      console.error('‚ùå Erreur traitement message WebSocket:', error);
      socket.send(JSON.stringify({
        type: 'error',
        message: 'Erreur traitement message'
      }));
    }
  };

  socket.onclose = () => {
    console.log("üîå WebSocket ultra-optimis√© ferm√©");
  };

  socket.onerror = (error) => {
    console.error("‚ùå Erreur WebSocket ultra-optimis√©:", error);
  };

  return response;
});
